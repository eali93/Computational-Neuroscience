{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robert-lamprecht/Computational-Neuroscience/blob/main/CompNeuroProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTkN2CDFCWbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "076d7a6b-3e2c-400a-ce84-7cc61300c4a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install Libraries\n",
        "!pip install numpy scipy scikit-learn --quiet\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import scipy\n",
        "import scipy.io #enables uploading of .mat files\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import mutual_info_classif #for MI analysis\n",
        "import math\n",
        "from scipy import stats as st\n",
        "from scipy import signal\n",
        "from scipy import interpolate\n",
        "from scipy.io import loadmat\n",
        "print(\"Libraries loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load .mat files in in Python\n",
        "import scipy.io\n",
        "dat = scipy.io.loadmat('t5.2019.05.08_singleLetters.mat') #load single letters file\n",
        "mouseTemplate = scipy.io.loadmat('computerMouseTemplates.mat') #load handwriting file\n"
      ],
      "metadata": {
        "id": "a3JvfSg7KyR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Function\n",
        "def gaussSmooth_fast(timeSeries, width):\n",
        "    if width == 0:\n",
        "        return timeSeries\n",
        "\n",
        "    wingSize = math.ceil(width * 5)\n",
        "    # Range from -wingSize to wingSize inclusive\n",
        "    x_range = np.arange(-wingSize, wingSize + 1)\n",
        "    gKernel = st.norm.pdf(x_range, 0, width)\n",
        "    # In Python, we don't need the conjugate transpose (conj().T)\n",
        "    # since we're working with real values\n",
        "\n",
        "    normFactor = np.cumsum(gKernel)\n",
        "    test = np.vstack((timeSeries, np.zeros((len(gKernel)-1, timeSeries.shape[1]))))\n",
        "\n",
        "    # Apply the filter\n",
        "    Y = signal.lfilter(gKernel, [1], test)\n",
        "\n",
        "    # Division operations (equivalent of bsxfun in MATLAB)\n",
        "    Y[0:len(gKernel)-1, :] = Y[0:len(gKernel)-1, :] / normFactor[0:len(normFactor)-1, np.newaxis]\n",
        "    Y[-(len(gKernel)-1):, :] = Y[-(len(gKernel)-1):, :] / np.flip(normFactor[0:len(normFactor)-1, np.newaxis], axis=0)\n",
        "\n",
        "    # Extract the relevant part (equivalent to the last line in MATLAB)\n",
        "    midpoint = (len(gKernel) - 1) // 2\n",
        "    Y = Y[midpoint:-(len(gKernel)-1-midpoint), :]\n",
        "\n",
        "    return Y"
      ],
      "metadata": {
        "id": "sBTbstWXL8KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Function\n",
        "def tsne_warp_dist(d1, d2_mat, n_time_bins_per_trial):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    d1 : numpy.ndarray\n",
        "        A 1 x N vector representing a single data point that has been\n",
        "        'unrolled' from a matrix (T x D) into a vector (1 x TD), where T is\n",
        "        the number of time bins and D is the number of neural dimensions.\n",
        "\n",
        "    d2_mat : numpy.ndarray\n",
        "        An M x N matrix, where each row is a data point.\n",
        "\n",
        "    n_time_bins_per_trial : int\n",
        "        Specifies how many time bins (T) are included in each data point.\n",
        "        The number of neural dimensions is then D = N/T.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    warp_dist : numpy.ndarray\n",
        "        An M x 1 vector representing the distance between d1 and each row of d2.\n",
        "    \"\"\"\n",
        "    # affineWarps is a vector of alpha values to consider\n",
        "    affine_warps = np.linspace(0.7, 1.42, 15)\n",
        "\n",
        "    # infer the number of neural dimensions per data point\n",
        "    n_neural_dim = len(d1) // n_time_bins_per_trial\n",
        "\n",
        "    # reshape d1 into a T x D matrix\n",
        "    d1 = d1.reshape(n_time_bins_per_trial, n_neural_dim)\n",
        "\n",
        "    # eDist represents the euclidean distance between d1 and all rows of d2\n",
        "    # for each alpha\n",
        "    e_dist = np.zeros((d2_mat.shape[0], len(affine_warps)))\n",
        "\n",
        "    # now we fill in eDist one entry at a time\n",
        "    for a in range(len(affine_warps)):\n",
        "        # linearly warp d1 using this alpha\n",
        "        x_orig = np.arange(1, d1.shape[0] + 1)\n",
        "        x_interp = np.linspace(1, d1.shape[0], int(affine_warps[a] * d1.shape[0]))\n",
        "        d1_interp = interpolate.interp1d(x_orig, d1, axis=0)(x_interp)\n",
        "\n",
        "        # compute the euclidean distance between the warped d1 and all points in d2\n",
        "        for row_idx in range(d2_mat.shape[0]):\n",
        "            # reshape d2 into a T x D matrix\n",
        "            d2 = d2_mat[row_idx, :].reshape(n_time_bins_per_trial, n_neural_dim)\n",
        "\n",
        "            # compute the euclidean distance, taking care to compute only\n",
        "            # over the relevant time points\n",
        "            if affine_warps[a] > 1:\n",
        "                df = d1_interp[:d1.shape[0], :] - d2\n",
        "            else:\n",
        "                df = d1_interp - d2[:d1_interp.shape[0], :]\n",
        "\n",
        "            e_dist[row_idx, a] = np.mean(df**2)\n",
        "\n",
        "    # the warp distance is defined as the minimum distance over all the\n",
        "    # alphas, which we take here\n",
        "    warp_dist = np.min(e_dist, axis=1)\n",
        "\n",
        "    return warp_dist"
      ],
      "metadata": {
        "id": "e-JERn6JPFLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to load files from google drive directly, if have shitty laptop\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bHx8lIHxbOPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1db9518-766b-4d40-9875-15b740ec671a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Time Warping & PCA\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Note: the filepath i use here is unique to my google drive, i couldnt figure out how to get\n",
        "# the google drive mount to work on shared folders so i copied the mat files to my drive for access\n",
        "dat = scipy.io.loadmat('/content/drive/MyDrive/Emory_Year_2/COMP NEURO/t5.2019.05.08_singleLetters.mat')\n",
        "letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',\n",
        "           'greaterThan','comma','apostrophe','tilde','questionMark']\n",
        "\n",
        "# Normalize the neural activity by blockwise z-scoring\n",
        "for letter in letters:\n",
        "    norm_cube = np.array(dat[f'neuralActivityCube_{letter}'], dtype=np.float32)\n",
        "\n",
        "    t_idx = np.arange(3)\n",
        "    for y in range(9):\n",
        "        mn = np.zeros((3, 1, 192))\n",
        "        mn[0, 0, :] = dat['meansPerBlock'][y, :]\n",
        "        mn[1, 0, :] = dat['meansPerBlock'][y, :]\n",
        "        mn[2, 0, :] = dat['meansPerBlock'][y, :]\n",
        "\n",
        "        sd = np.zeros((1, 1, 192))\n",
        "        sd[0, 0, :] = dat['stdAcrossAllData']\n",
        "\n",
        "        norm_cube[t_idx, :, :] -= mn\n",
        "        norm_cube[t_idx, :, :] /= sd\n",
        "        t_idx += 3\n",
        "\n",
        "    dat[f'neuralActivityCube_{letter}'] = norm_cube\n",
        "# Compute trial-averaged activity for each character\n",
        "all_data = np.zeros((2000, 27264))\n",
        "all_spatial = np.zeros((200000, 192))\n",
        "all_labels = np.zeros(2000, dtype=int)\n",
        "all_avg = []\n",
        "c_idx = 0\n",
        "spatial_idx = 0\n",
        "\n"
      ],
      "metadata": {
        "id": "5EKhl-tRBK5K",
        "outputId": "d1956116-8acf-429b-c3f4-4d20bb966526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-929b8a598c8e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Time Warping & PCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgaussian_filter1d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0m_distributor_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_chunking.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_is_arraylike_not_scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_get_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPositiveSpectrumWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_is_numpy_namespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_preserve_dia_indices_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0m_NUMPY_NAMESPACE_NAMES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"array_api_compat.numpy\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_init\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m from pandas.core.api import (\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;31m# dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mArrowDtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m from pandas.core.groupby import (\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mGrouper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mNamedAgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.core.groupby.generic import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mDataFrameGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mNamedAgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mSeriesGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m from pandas.core.groupby import (\n\u001b[1;32m     70\u001b[0m     \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0msanitize_masked_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m )\n\u001b[0;32m--> 149\u001b[0;31m from pandas.core.generic import (\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0mNDFrame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mmake_doc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    150\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m from pandas.core import (\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0malgorithms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0marraylike\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mlength_of_indexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m )\n\u001b[0;32m---> 79\u001b[0;31m from pandas.core.indexes.api import (\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mMultiIndex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCategoricalIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetimes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIntervalIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPeriodIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/interval.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0minherit_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m )\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m from pandas.core.indexes.timedeltas import (\n\u001b[1;32m     86\u001b[0m     \u001b[0mTimedeltaIndex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(data, name, bytecode_path, source_path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#t-SNE and KNN\n",
        "\n",
        "#list of letters\n",
        "letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w','x','y','z', 'greaterThan','comma','apostrophe','tilde','questionMark']\n",
        "\n",
        "#normalize the neural activity by blockwise z-scoring\n",
        "for letter in letters:\n",
        "    normCube = np.float32(dat['neuralActivityCube' + letter])\n",
        "\n"
      ],
      "metadata": {
        "id": "YyoyierBcW9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca63b1c7-188b-4480-e49a-eb941012b225",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neuralActivityCubea\n",
            "neuralActivityCubeb\n",
            "neuralActivityCubec\n",
            "neuralActivityCubed\n",
            "neuralActivityCubee\n",
            "neuralActivityCubef\n",
            "neuralActivityCubeg\n",
            "neuralActivityCubeh\n",
            "neuralActivityCubei\n",
            "neuralActivityCubej\n",
            "neuralActivityCubek\n",
            "neuralActivityCubel\n",
            "neuralActivityCubem\n",
            "neuralActivityCuben\n",
            "neuralActivityCubeo\n",
            "neuralActivityCubep\n",
            "neuralActivityCubeq\n",
            "neuralActivityCuber\n",
            "neuralActivityCubes\n",
            "neuralActivityCubet\n",
            "neuralActivityCubeu\n",
            "neuralActivityCubev\n",
            "neuralActivityCubew\n",
            "neuralActivityCubex\n",
            "neuralActivityCubey\n",
            "neuralActivityCubez\n",
            "neuralActivityCubegreaterThan\n",
            "neuralActivityCubecomma\n",
            "neuralActivityCubeapostrophe\n",
            "neuralActivityCubetilde\n",
            "neuralActivityCubequestionMark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Function\n",
        "\n",
        "def getHandwritingCharacterDefinitions():\n",
        "  \"\"\"\n",
        "  Returns a dictionary with entries that define the names of each character, its length, and where the pen tip begins.\n",
        "\n",
        "  Returns:\n",
        "      charDef(dict)\n",
        "  \"\"\"\n",
        "\n",
        "  charDef = {}\n",
        "\n",
        "  # Define the list of all 31 characters and their names\n",
        "  charDef['charList'] = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',\n",
        "                'greaterThan','comma','apostrophe','tilde','questionMark']\n",
        "  charDef['charListAbbr'] = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',\n",
        "                '>',',',\"'\",'~','?']\n",
        "\n",
        "  # Define the length of each character (in # of 10 ms bins) to use for each template.\n",
        "  # These were hand-defined based on visual inspection of the reconstructed pen trajectories.\n",
        "  charDef['charLen'] = np.array([99, 91, 70, 104, 98, 125, 110, 104, 79, 92, 127, 68, 132, 90,\n",
        "                        84, 113, 104, 74, 86, 110, 86, 83, 110, 103, 115, 100, 82, 77, 116, 71, 110]).astype(np.int32)\n",
        "\n",
        "  # For each character, this defines the starting location of the pen tip (0 = bottom of the line, 1 = top)\n",
        "  charDef['penStart'] = [0.25, 1, 0.5, 0.5, 0.25, 1.0, 0.25, 1.0, 0.5, 0.5, 1, 1, 0.5, 0.5, 0.25, 0.5, 0.25, 0.5, 0.5, 1,\n",
        "           0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.25, 1, 0.5, 1]\n",
        "\n",
        "  # Dictionary to convert string representation to character index\n",
        "  charDef['strToCharIdx'] = {}\n",
        "  for x in range(len(charDef['charListAbbr'])):\n",
        "    charDef['strToCharIdx'][charDef['charListAbbr'][x]] = x\n",
        "\n",
        "  return charDef\n"
      ],
      "metadata": {
        "id": "QsZtnrGYuvKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Time-warping the single letters data for linear decoding of pen tip velocities\n",
        "\n",
        "# Install and load the updated time-warping package (\"Piecewise Linear Time Warping\")\n",
        "!pip install git+https://github.com/ahwillia/affinewarp.git\n",
        "\n",
        "import affinewarp as aw\n",
        "import scipy.io\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "from affinewarp.piecewisewarp import PiecewiseWarping # Piecewise warping is the closest warping function to the TWPCA done in the paper\n",
        "import os\n",
        "\n",
        "dat = scipy.io.loadmat('/content/drive/My Drive/Comp Neuro Project/t5.2019.05.08_singleLetters.mat')"
      ],
      "metadata": {
        "id": "1j6bkfaxIGn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "2102e7e3-0529-4c46-fd0b-13ddb16394f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ahwillia/affinewarp.git\n",
            "  Cloning https://github.com/ahwillia/affinewarp.git to /tmp/pip-req-build-o2sinm9t\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ahwillia/affinewarp.git /tmp/pip-req-build-o2sinm9t\n",
            "  Resolved https://github.com/ahwillia/affinewarp.git to commit 23f9e643d2e74ad930ef283311c2c14c585eb6b9\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.11/dist-packages (from affinewarp==0.2.0) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from affinewarp==0.2.0) (1.14.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from affinewarp==0.2.0) (3.10.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from affinewarp==0.2.0) (0.60.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from affinewarp==0.2.0) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from affinewarp==0.2.0) (1.6.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from affinewarp==0.2.0) (8.3.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->affinewarp==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->affinewarp==0.2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->affinewarp==0.2.0) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->affinewarp==0.2.0) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->affinewarp==0.2.0) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->affinewarp==0.2.0) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->affinewarp==0.2.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->affinewarp==0.2.0) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->affinewarp==0.2.0) (0.43.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->affinewarp==0.2.0) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->affinewarp==0.2.0) (1.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->affinewarp==0.2.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->affinewarp==0.2.0) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->affinewarp==0.2.0) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Time-warping the single letters data cont'd\n",
        "\n",
        "# Defines the list of all 31 characters and what to call then\n",
        "charDef = getHandwritingCharacterDefinitions()\n",
        "\n",
        "\n",
        "# Pre-processing and Normalizing\n",
        "\n",
        "# Because baseline firing rates drift over time, we normalize each electrode's firing rate by subtracting its mean firing rate within each block of data (re-centering it).\n",
        "# We also divide by each electrode's standard deviation to normalize the units.\n",
        "\n",
        "for char in charDef['charList']:\n",
        "    neuralCube = dat['neuralActivityCube_' + char].astype(np.float64)\n",
        "\n",
        "    # get the trials that belong to this character\n",
        "    trlIdx = []\n",
        "    for t in range(dat['characterCues'].shape[0]):\n",
        "      if dat['characterCues'][t,0] == char:\n",
        "        trlIdx.append(t)\n",
        "\n",
        "    # get the block that each trial\n",
        "    blockIdx = dat['blockNumsTimeSeries'][dat['goPeriodOnsetTimeBin'][trlIdx]]\n",
        "    blockIdx = np.squeeze(blockIdx)\n",
        "\n",
        "    # subtract block-specific means from each trial\n",
        "    for b in range(dat['blockList'].shape[0]):\n",
        "      trialsFromThisBlock = np.squeeze(blockIdx == dat['blockList'][b])\n",
        "      neuralCube[trialsFromThisBlock, :, :] -= dat['meansPerBlock'][np.newaxis, b, :]\n",
        "\n",
        "    # divide by standard deviation to normalize the units\n",
        "    neuralCube = neuralCube / dat['stdAcrossAllData'][np.newaxis, :, :]\n",
        "\n",
        "    # save the normalized neural cube in the same dataset\n",
        "    dat['normalized_neuralActivityCube_' + char] = neuralCube\n",
        "\n",
        "# Warp each character\n",
        "\n",
        "alignedDat = {}\n",
        "\n",
        "for char in charDef['charList']:\n",
        "    print('Warping character: ' + char)\n",
        "\n",
        "    # clears the previous character's graph\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    # smooths the binned spike counts before time-warping to denoise them\n",
        "    smoothed_spikes = scipy.ndimage.filters.gaussian_filter1d(dat['normalized_neuralActivityCube_' + char], 3.0, axis = 1)\n",
        "\n",
        "    # fit the piecewise-affine time warping model\n",
        "    model = PiecewiseWarping(n_knots = 5, warp_reg_scale = 0.01, smoothness_reg_scale = 0.01)\n",
        "    model.fit(smoothed_spikes)\n",
        "\n",
        "    # use the model object to align data\n",
        "    estimated_aligned_data = model.transform(dat['normalized_neuralActivityCube_' + char])\n",
        "    smoothed_agligned_data = scipy.ndimage.filters.gaussian_filter1d(estimated_aligned_data, 3.0, axis = 1)\n",
        "\n",
        "    # store aligned data and time-warping functions\n",
        "    alignedDat[char] = estimated_aligned_data\n",
        "    alignedDat[char + '_T'] = model.params['warp'].T.copy()\n",
        "\n",
        "    # plot the warping functions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "krMDDj2JGVTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reconstruct letter trajectories from neural activity\n",
        "\n",
        "# Noticed that this script actually imports warped data from the \"Step1_timeWarp\" they did - will come back working on this Monday (4/14) afternoon\n",
        "\n",
        "# save the letters\n",
        "letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j','k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't','u', 'v', 'w', 'x', 'y', 'z',\n",
        "    'greaterThan', 'comma', 'apostrophe', 'tilde', 'questionMark']\n",
        "\n",
        "# fix the 'o' and 'x' templates which don't match T5's writing style\n",
        "\n",
        "## 1. rotation matrix for -90 degrees:\n",
        "theta = -90 * np.pi / 180  # convert to radians\n",
        "rot90 = np.array([[np.cos(theta), np.cos(0)],[np.sin(theta), np.sin(0)]])\n",
        "\n",
        "## apply rotation to the first two columns of the 'o' template\n",
        "\n",
        "mouseTemplates['o'][:, 0:2] = (rot90 @ mouseTemplates['o'][:, 0:2].T).T\n",
        "\n",
        "## 2. set y = -x for indices 22 to 43\n",
        "mouseTemplates['x'][21:43, 1] = -mouseTemplates['x'][21:43, 0]\n",
        "\n",
        "## flip x and y for indices 47 to 68\n",
        "mouseTemplates['x'][46:68, 0:2] = -mouseTemplates['x'][46:68, 0:2]\n",
        "\n"
      ],
      "metadata": {
        "id": "Z7k4QnKJXhYA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}